{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn1d-lstm",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjeevKV/LearningKeras/blob/master/cnn1d_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1y_D96OXGu8",
        "colab_type": "code",
        "outputId": "3dd91f29-f61e-420a-b645-a8806d6e3f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r8ze84acNuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from scipy.io import wavfile as wav\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dense, Activation, Flatten, LSTM\n",
        "from keras import optimizers\n",
        "import argparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "peCw0WbRcB4Y",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "fps - Frames per second\n",
        "num_steps - Number of frames in one sample (in seconds)\n",
        "skip_step - Number of frames to skip before next sample starts (in seconds)\n",
        "\"\"\"\n",
        "class KerasCnnBatchGenerator(object):\n",
        "    def __init__(self, audio_data_path, motion_data_path, num_steps, batch_size, fps = 8000, skip_step=0.5, out_size = 1):\n",
        "        #List all the files in the path - Both Audio and Motion\n",
        "        self.audio_data_path = audio_data_path\n",
        "        self.motion_data_path = motion_data_path\n",
        "        self.audio_data_files = sorted(os.listdir(self.audio_data_path))\n",
        "        self.motion_data_files = sorted(os.listdir(self.motion_data_path))\n",
        "        \n",
        "        if len(self.audio_data_files) != len(self.motion_data_files):\n",
        "            sys.exit(\"Audio and Motion data files should be equal in number\")\n",
        "            \n",
        "        self.total_files = len(self.audio_data_files)\n",
        "        self.current_file_idx = 0\n",
        "        \n",
        "        self.assign_audio_frame_for_current_file() # Current Audio File's data - Assigned to self.audio_data\n",
        "        self.assign_motion_frame_for_current_file() # Current Motion File's data - Assigned to self.motion_data\n",
        "        self.num_steps = int(num_steps * fps)\n",
        "        self.batch_size = batch_size\n",
        "        self.fps = fps\n",
        "        # this will track the progress of the batches sequentially through the\n",
        "        # data set - once the data reaches the end of the data set it will reset\n",
        "        # back to zero\n",
        "        self.current_idx = 0\n",
        "        # skip_step is the number of words which will be skipped before the next\n",
        "        # batch is skimmed from the data set\n",
        "        self.skip_step = skip_step * fps\n",
        "        self.out_size = out_size\n",
        "\n",
        "        self.num_steps_sec = num_steps\n",
        "        self.skip_step_sec = skip_step\n",
        "        self.median_velocity = self.motion_data[\"velocity\"].median()\n",
        "        self.mean_velocity = self.motion_data[\"velocity\"].mean()\n",
        "        self.median_avg_velocities = self.get_mean_avg_velocities()\n",
        "        \n",
        "    def get_mean_avg_velocities(self):\n",
        "        velocities = []\n",
        "        for i in np.arange(0,max(self.motion_data[\"timestamp\"]), self.skip_step_sec):\n",
        "            relevant_y = self.motion_data[(self.motion_data[\"timestamp\"] >= i) & \n",
        "                                              (self.motion_data[\"end_timestamp\"] < i + self.num_steps_sec)]\n",
        "            velocities.append(relevant_y[\"velocity\"].values.mean())\n",
        "        return np.median(velocities)\n",
        "\n",
        "    def assign_audio_frame_for_current_file(self):\n",
        "        fps, audio_clip = wav.read(os.path.join(self.audio_data_path, self.audio_data_files[self.current_file_idx]))\n",
        "        audio_clip = audio_clip / max(np.abs(audio_clip))\n",
        "        self.audio_data = pd.DataFrame(audio_clip, columns = [\"audio\"])\n",
        "        \n",
        "    def assign_motion_frame_for_current_file(self):\n",
        "        coords = pd.read_csv(os.path.join(self.motion_data_path, self.motion_data_files[self.current_file_idx]))\n",
        "        coords[\"end_timestamp\"] = coords[\" timestamp\"].shift(-1)\n",
        "        coords[\"timestamp\"] = coords[\" timestamp\"]\n",
        "        imp_coords = coords[[\"timestamp\", \"end_timestamp\", \" X_0\", \" Y_0\", \" Z_0\"]]\n",
        "        coords = pd.DataFrame(np.asarray(imp_coords), columns = [\"timestamp\", \"end_timestamp\", \"X_0\", \"Y_0\", \"Z_0\"])\n",
        "        coords[\"velocity\"] = (coords[\"X_0\"] - coords[\"X_0\"].shift(-1)) ** 2 + \\\n",
        "                                (coords[\"Y_0\"] - coords[\"Y_0\"].shift(-1)) ** 2 + \\\n",
        "                                (coords[\"Z_0\"] - coords[\"Z_0\"].shift(-1)) ** 2\n",
        "        coords[\"velocity\"] = np.sqrt(coords[\"velocity\"])\n",
        "        self.motion_data = coords        \n",
        "\n",
        "    def assign_angular_frame_for_current_file(self):\n",
        "        coords = pd.read_csv(os.path.join(self.motion_data_path, self.motion_data_files[self.current_file_idx]))\n",
        "        coords[\"end_timestamp\"] = coords[\" timestamp\"].shift(-1)\n",
        "        coords[\"timestamp\"] = coords[\" timestamp\"]\n",
        "        imp_coords = coords[[\"timestamp\", \"end_timestamp\", \" p_rx\"]]\n",
        "        coords = pd.DataFrame(np.asarray(imp_coords), columns = [\"timestamp\", \"end_timestamp\", \"p_rx\"])\n",
        "        coords[\"velocity\"] = (coords[\"p_rx\"] - coords[\"p_rx\"].shift(-1)) \n",
        "        self.motion_data = coords  \n",
        "        \n",
        "    def generate(self):\n",
        "        x = np.zeros((self.batch_size, self.num_steps, 1))\n",
        "        y = np.zeros((self.batch_size, self.out_size))\n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.audio_data):\n",
        "                    # reset the index back to the start of the data set\n",
        "                    self.current_idx = 0\n",
        "                    self.current_file_idx = (self.current_file_idx + 1) % self.total_files\n",
        "                    self.assign_audio_frame_for_current_file()\n",
        "                    self.assign_motion_frame_for_current_file()\n",
        "                    \n",
        "                    self.median_velocity = self.motion_data[\"velocity\"].median()\n",
        "                    self.mean_velocity = self.motion_data[\"velocity\"].mean()\n",
        "                    self.median_avg_velocities = self.get_mean_avg_velocities()\n",
        "                    \n",
        "                x[i, :, :] = self.audio_data.loc[self.current_idx:self.current_idx + self.num_steps - 1][\"audio\"].values.reshape((-1,1))\n",
        "                current_idx_sec = self.current_idx / self.fps\n",
        "                relevant_y = self.motion_data[(self.motion_data[\"timestamp\"] >= current_idx_sec) & \n",
        "                                              (self.motion_data[\"end_timestamp\"] < current_idx_sec + self.num_steps_sec)]\n",
        "                \n",
        "                y[i, :] = to_categorical(int(relevant_y[\"velocity\"].values.mean() > self.median_avg_velocities), num_classes = 2)\n",
        "                self.current_idx += self.skip_step\n",
        "            yield x, y\n",
        "            \n",
        "    def generate_angular_data(self):\n",
        "        x = np.zeros((self.batch_size, self.num_steps, 1))\n",
        "        y = np.zeros((self.batch_size, self.out_size))\n",
        "        self.assign_angular_frame_for_current_file()\n",
        "        while True:\n",
        "            for i in range(self.batch_size):\n",
        "                if self.current_idx + self.num_steps >= len(self.audio_data):\n",
        "                    # reset the index back to the start of the data set\n",
        "                    self.current_idx = 0\n",
        "                    self.current_file_idx = (self.current_file_idx + 1) % self.total_files\n",
        "                    self.assign_audio_frame_for_current_file()\n",
        "                    self.assign_angular_frame_for_current_file()\n",
        "                    \n",
        "                    self.median_velocity = self.motion_data[\"velocity\"].median()\n",
        "                    self.mean_velocity = self.motion_data[\"velocity\"].mean()\n",
        "                    self.median_avg_velocities = self.get_mean_avg_velocities()\n",
        "                    \n",
        "                x[i, :, :] = self.audio_data.loc[self.current_idx:self.current_idx + self.num_steps - 1][\"audio\"].values.reshape((-1,1))\n",
        "                current_idx_sec = self.current_idx / self.fps\n",
        "                relevant_y = self.motion_data[(self.motion_data[\"timestamp\"] >= current_idx_sec) & \n",
        "                                              (self.motion_data[\"end_timestamp\"] < current_idx_sec + self.num_steps_sec)]\n",
        "                \n",
        "                y[i, :] = to_categorical(int(relevant_y[\"velocity\"].values.mean() > self.median_avg_velocities), num_classes = 2)\n",
        "                self.current_idx += self.skip_step\n",
        "            yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSgZ2E3GS4NK",
        "colab_type": "code",
        "outputId": "2cb8c43a-9db7-4a18-f736-df17ec83d8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "! ls \"/content/drive/My Drive/Data\""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "open_face_audio        test_face_coordinates   valid_face_audio\n",
            "open_face_coordinates  train_face_audio        valid_face_coordinates\n",
            "test_face_audio        train_face_coordinates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FxSCqsRUH_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn1d(input_shape, num_classes):\n",
        "    CONV_1D_KERNEL_SIZE = 20\n",
        "    model = Sequential(name='Emo1D')\n",
        "    \t\n",
        "    # LFLB1\n",
        "    model.add(Conv1D(filters = 64,kernel_size = (CONV_1D_KERNEL_SIZE),strides=1,padding='same',data_format='channels_last',input_shape=input_shape))\t\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "    \n",
        "    #LFLB2\n",
        "    model.add(Conv1D(filters=64, kernel_size = CONV_1D_KERNEL_SIZE, strides=1,padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "    \n",
        "    #LFLB3\n",
        "    model.add(Conv1D(filters=128, kernel_size = CONV_1D_KERNEL_SIZE, strides=1,padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "    \n",
        "    #LFLB4\n",
        "    model.add(Conv1D(filters=128, kernel_size = CONV_1D_KERNEL_SIZE, strides=1,padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "    \t\t\n",
        "    #LSTM\n",
        "    model.add(LSTM(units = 64))\n",
        "    #FC\n",
        "    #model.add(Flatten())\n",
        "    #model.add(Dense(units = 8, activation = 'relu'))\n",
        "    #model.add(Dense(units = 8, activation = 'relu'))\n",
        "    model.add(Dense(units=num_classes,activation='softmax'))\n",
        "    \n",
        "    #Model compilation\t\n",
        "    opt = optimizers.SGD(lr = learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "    \t\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhyaeAbyUKiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "a185e079-d188-4cf1-8d60-c4f9e77aae27"
      },
      "source": [
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#args = parser.parse_args()\n",
        "\n",
        "num_fc = 64\n",
        "batch_size = 32\n",
        "num_epochs = 1500 #best model will be saved before number of epochs reach this value\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "train_generator_obj = KerasCnnBatchGenerator('/content/drive/My Drive/Data/train_face_audio/', '/content/drive/My Drive/Data/train_face_coordinates/', 10, 30, fps = 8000, skip_step=1, out_size = 2)\n",
        "valid_generator_obj = KerasCnnBatchGenerator('/content/drive/My Drive/Data/valid_face_audio/', '/content/drive/My Drive/Data/valid_face_coordinates/', 10, 1, fps = 8000, skip_step=10, out_size = 2)\n",
        "\n",
        "model = cnn1d(input_shape=(train_generator_obj.num_steps, 1),num_classes=2)\n",
        "model.summary()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_33 (Conv1D)           (None, 80000, 64)         1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 80000, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 80000, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 20000, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 20000, 64)         81984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 20000, 64)         256       \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 20000, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_34 (MaxPooling (None, 5000, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_35 (Conv1D)           (None, 5000, 128)         163968    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 5000, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 5000, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 1250, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 1250, 128)         327808    \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 1250, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 1250, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_36 (MaxPooling (None, 312, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 626,178\n",
            "Trainable params: 625,410\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPDWKbDmloK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "98539419-ba06-4fa9-8cea-6013787ddd98"
      },
      "source": [
        "model.fit_generator(generator = train_generator_obj.generate_angular_data(), epochs = 10, verbose = 2, steps_per_epoch = 60,\n",
        "                    validation_data = valid_generator_obj.generate_angular_data(), validation_steps = 60)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " - 103s - loss: 0.6843 - categorical_accuracy: 0.5572 - val_loss: 0.6036 - val_categorical_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            " - 94s - loss: 0.6718 - categorical_accuracy: 0.5844 - val_loss: 0.6275 - val_categorical_accuracy: 0.7000\n",
            "Epoch 3/10\n",
            " - 93s - loss: 0.6644 - categorical_accuracy: 0.6044 - val_loss: 0.6037 - val_categorical_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            " - 93s - loss: 0.6584 - categorical_accuracy: 0.6128 - val_loss: 0.5958 - val_categorical_accuracy: 0.7333\n",
            "Epoch 5/10\n",
            " - 93s - loss: 0.6525 - categorical_accuracy: 0.6222 - val_loss: 0.6148 - val_categorical_accuracy: 0.6833\n",
            "Epoch 6/10\n",
            " - 93s - loss: 0.6458 - categorical_accuracy: 0.6350 - val_loss: 0.5983 - val_categorical_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            " - 91s - loss: 0.6372 - categorical_accuracy: 0.6539 - val_loss: 0.5918 - val_categorical_accuracy: 0.7000\n",
            "Epoch 8/10\n",
            " - 93s - loss: 0.6318 - categorical_accuracy: 0.6539 - val_loss: 0.5815 - val_categorical_accuracy: 0.7167\n",
            "Epoch 9/10\n",
            " - 92s - loss: 0.6302 - categorical_accuracy: 0.6600 - val_loss: 0.5729 - val_categorical_accuracy: 0.7167\n",
            "Epoch 10/10\n",
            " - 93s - loss: 0.6285 - categorical_accuracy: 0.6594 - val_loss: 0.6141 - val_categorical_accuracy: 0.6833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda1c7c9f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ZEO-uQW6S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator_obj = KerasCnnBatchGenerator('/content/drive/My Drive/Data/test_face_audio/', '/content/drive/My Drive/Data/test_face_coordinates/', 10, 1, fps = 8000, skip_step=10, out_size = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cxNoj0xXJWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "652883b3-c154-4fc0-da4b-3bb593b5ebac"
      },
      "source": [
        "model.evaluate_generator(test_generator_obj.generate_angular_data(), steps = 60)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5800722390413284, 0.7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_WnlG2sc8AV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5108a768-f049-4914-9ae3-45c97c5eef93"
      },
      "source": [
        "i%tb"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No traceback available to show.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiocudk5dTZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generatr = train_generator_obj.generate_angular_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZrJ8z5hehxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f30a473-72b2-45bc-b036-b19a20fe0c00"
      },
      "source": [
        "next(generatr)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 0.00545045],\n",
              "         [ 0.00167706],\n",
              "         [ 0.00099575],\n",
              "         ...,\n",
              "         [ 0.05702007],\n",
              "         [ 0.05665322],\n",
              "         [ 0.09412505]],\n",
              " \n",
              "        [[-0.00414024],\n",
              "         [-0.01273518],\n",
              "         [-0.015408  ],\n",
              "         ...,\n",
              "         [-0.08615901],\n",
              "         [-0.05644358],\n",
              "         [-0.00497877]],\n",
              " \n",
              "        [[ 0.00235837],\n",
              "         [-0.00230596],\n",
              "         [-0.00403543],\n",
              "         ...,\n",
              "         [ 0.13772863],\n",
              "         [ 0.17504324],\n",
              "         [ 0.14600912]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.0713275 ],\n",
              "         [-0.26162151],\n",
              "         [-0.47088727],\n",
              "         ...,\n",
              "         [ 0.00917143],\n",
              "         [ 0.00880457],\n",
              "         [ 0.00214873]],\n",
              " \n",
              "        [[-0.20591164],\n",
              "         [-0.46166343],\n",
              "         [-0.02777632],\n",
              "         ...,\n",
              "         [ 0.14286463],\n",
              "         [ 0.02195902],\n",
              "         [-0.06309942]],\n",
              " \n",
              "        [[-0.05366595],\n",
              "         [ 0.01509355],\n",
              "         [-0.03417012],\n",
              "         ...,\n",
              "         [ 0.01037681],\n",
              "         [ 0.00361616],\n",
              "         [ 0.01084849]]]), array([[0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.],\n",
              "        [1., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-yCm7WCgxh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}